{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMg5cxddLDMXO1JhqFvdC4p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaisshnavee1410/ASSIGNMENT-5-EDA_1-.ipynb/blob/main/EDA_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **EXPLORATORY DATA ANALYSIS ON A DATASET**"
      ],
      "metadata": {
        "id": "IWDGipeOE4-m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OBJECTIVE:**"
      ],
      "metadata": {
        "id": "njx0Qxf7cKcm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main goal of this assignment is to conduct a thorough exploratory analysis of the\n",
        "\"cardiographic.csv\" dataset to uncover insights, identify patterns, and understand the dataset's\n",
        "underlying structure. You will use statistical summaries, visualizations, and data manipulation\n",
        "techniques to explore the dataset comprehensively."
      ],
      "metadata": {
        "id": "eZCDVw6UcHsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"Cardiotocographic.csv\")"
      ],
      "metadata": {
        "id": "wN8nDDVaipfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset information\n",
        "print(\"Dataset Information:\")\n",
        "print(df.info())\n",
        "\n",
        "#Display first few rows\n",
        "print(\"\\nFirst 5 Rows of Dataset:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "cAzMToEsn3yI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **DATASET**"
      ],
      "metadata": {
        "id": "f8vuJyMgpZFy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **LB** - Likely stands for \"Baseline Fetal Heart Rate (FHR)\" which represents the average fetal\n",
        "heart rate over a period.\n",
        "\n",
        "2. **AC** - Could represent \"Accelerations\" in the FHR. Accelerations are usually a sign of fetal\n",
        "well-being.\n",
        "\n",
        "3. **FM** - May indicate \"Fetal Movements\" detected by the monitor.\n",
        "\n",
        "4. **UC** - Likely denotes \"Uterine Contractions\", which can impact the FHR pattern.\n",
        "\n",
        "5. **DL** - Could stand for \"Decelerations Late\" with respect to uterine contractions, which can\n",
        "be a sign of fetal distress.\n",
        "\n",
        "6. **DS** - May represent \"Decelerations Short\" or decelerations of brief duration.\n",
        "\n",
        "7. **DP** - Could indicate \"Decelerations Prolonged\", or long-lasting decelerations.\n",
        "\n",
        "8. **ASTV** - Might refer to \"Percentage of Time with Abnormal Short Term Variability\" in the\n",
        "FHR.\n",
        "\n",
        "9. **MSTV** - Likely stands for \"Mean Value of Short Term Variability\" in the FHR.\n",
        "\n",
        "10. **ALTV** - Could represent \"Percentage of Time with Abnormal Long Term Variability\" in the\n",
        "FHR.\n",
        "\n",
        "11. **MLTV** - Might indicate \"Mean Value of Long Term Variability\" in the FHR."
      ],
      "metadata": {
        "id": "buyfIwQVoDdf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TASKS**"
      ],
      "metadata": {
        "id": "aT_em5xKp63h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  **1.**   **DATA CLEANING AND PREPARATION:**"
      ],
      "metadata": {
        "id": "5pgdi_lrp_YC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(\"Cardiotocographic.csv\")\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"\\nMissing Values in Each Column:\")\n",
        "print(missing_values)\n"
      ],
      "metadata": {
        "id": "C1J7zlNdn3vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values (Imputation or Deletion)\n",
        "# If missing values exist, we can choose to fill them with mean/median or drop them\n",
        "df.fillna(df.median(), inplace=True)  # Filling missing values with column median\n",
        "print(\"\\nMissing values after handling:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "IxPAmdwin3s2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check data types before conversion\n",
        "print(\"\\nData Types Before Conversion:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Convert object (string) types to numeric if necessary\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':  # Convert numeric columns stored as strings\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce')\n"
      ],
      "metadata": {
        "id": "q-VgiMgTn3pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nData Types After Conversion:\")\n",
        "print(df.dtypes)\n",
        "\n",
        "# Summary statistics before handling outliers\n",
        "print(\"\\nSummary Statistics Before Outlier Handling:\")\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "I8uGoujmn3kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify outliers (values outside 1.5 * IQR)\n",
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers = ((df < (Q3 - 1.5 * IQR)) | (df > (Q3 + 1.5 * IQR)))\n",
        "print(f\"\\nNumber of Outliers Detected: {outliers.sum().sum()}\")"
      ],
      "metadata": {
        "id": "9qzn7fl7C7ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove outliers\n",
        "df_cleaned = df[~outliers.any(axis=1)]\n",
        "\n",
        "print(f\"\\nRows before outlier removal: {df.shape[0]}\")\n",
        "print(f\"Rows after outlier removal: {df_cleaned.shape[0]}\")"
      ],
      "metadata": {
        "id": "qBBtfrgbrO-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boxplot to visualize outliers\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.boxplot(data=df_cleaned)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplot After Outlier Removal\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "igsS0kNJlO-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.STATISTICAL SUMMARY:**"
      ],
      "metadata": {
        "id": "Qn799c9suLd1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UE19fYblv7ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute statistical measures\n",
        "summary_stats = pd.DataFrame({\n",
        "    \"Mean\": df.mean(),\n",
        "    \"Median\": df.median(),\n",
        "    \"Standard Deviation\": df.std(),\n",
        "    \"IQR\": df.quantile(0.75) - df.quantile(0.25),\n",
        "    \"Min\": df.min(),\n",
        "    \"Max\": df.max()\n",
        "})"
      ],
      "metadata": {
        "id": "kxkwWX09uCaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the statistical summary\n",
        "print(\"Statistical Summary:\")\n",
        "print(summary_stats)"
      ],
      "metadata": {
        "id": "q7pE2l5tvTh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify interesting findings\n",
        "print(\"Interesting Findings:\")\n",
        "\n",
        "# Detect high variability\n",
        "high_variability = summary_stats[summary_stats[\"Standard Deviation\"] > summary_stats[\"Mean\"] * 0.5]\n",
        "if not high_variability.empty:\n",
        "    print(\"\\nColumns with High Variability (Std Dev > 50% of Mean):\")\n",
        "    print(high_variability)\n",
        "\n",
        "# Detect skewed distributions\n",
        "skewed_columns = summary_stats[abs(summary_stats[\"Mean\"] - summary_stats[\"Median\"]) > summary_stats[\"Standard Deviation\"]]\n",
        "if not skewed_columns.empty:\n",
        "    print(\"\\nColumns with Skewed Distribution (Mean ≠ Median):\")\n",
        "    print(skewed_columns)\n",
        "\n",
        "# Detect columns with extreme values\n",
        "large_range = summary_stats[(summary_stats[\"Max\"] - summary_stats[\"Min\"]) > summary_stats[\"Mean\"] * 5]\n",
        "if not large_range.empty:\n",
        "    print(\"\\nColumns with Large Range of Values:\")\n",
        "    print(large_range)"
      ],
      "metadata": {
        "id": "rhpRZh41wA93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.** **DATA VISUALIZATIONS:**"
      ],
      "metadata": {
        "id": "kGNFaLLLw_4U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Histograms\n",
        "plt.figure(figsize=(12, 8))\n",
        "df.hist(figsize=(12, 10), bins=20, color='skyblue')\n",
        "plt.suptitle(\"Histograms of Numerical Variables\", fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "# Boxplots\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=df, palette=\"coolwarm\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.title(\"Boxplots of Numerical Variables\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "S2-IoCA0yWi9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Bar Charts\n",
        "if 'Class' in df.columns:\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.countplot(x=df['Class'], palette=\"viridis\")\n",
        "    plt.title(\"Frequency of Categories\")\n",
        "    plt.xlabel(\"Category\")\n",
        "    plt.ylabel(\"Count\")\n",
        "    plt.show()\n",
        "\n",
        "# Pie Charts\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    df['Class'].value_counts().plot.pie(autopct='%1.1f%%', cmap='coolwarm', shadow=True)\n",
        "    plt.title(\"Distribution of Categorical Variable\")\n",
        "    plt.ylabel(\"\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "N1nYInMOyrGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scatter Plots & Correlation Heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Correlation Heatmap\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=df[\"LB\"], y=df[\"AC\"], hue=df[\"FM\"], palette=\"coolwarm\")\n",
        "plt.title(\"Scatter Plot of LB vs AC\")\n",
        "plt.xlabel(\"Baseline Fetal Heart Rate (LB)\")\n",
        "plt.ylabel(\"Accelerations (AC)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "f8BPzPxJ1k7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. PATTERN RECOGNITION AND INSIGHTS:**"
      ],
      "metadata": {
        "id": "kbKaDRON6LyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Correlation Analysis\n",
        "\n",
        "# Compute correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Display correlation heatmap\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n",
        "\n",
        "# Find highly correlated variables (above 0.7 or below -0.7)\n",
        "threshold = 0.7\n",
        "high_correlations = correlation_matrix[(correlation_matrix > threshold) | (correlation_matrix < -threshold)]\n",
        "print(\"\\nHighly Correlated Features (above 0.7 or below -0.7):\")\n",
        "print(high_correlations.dropna(how='all').dropna(axis=1, how='all'))"
      ],
      "metadata": {
        "id": "8CNkOPVK6XAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Identifying Trends Over Time (If Temporal Data Exists)\n",
        "\n",
        "# Check if a time-related column exists\n",
        "time_columns = [col for col in df.columns if \"time\" in col.lower() or \"date\" in col.lower()]\n",
        "if time_columns:\n",
        "    time_col = time_columns[0]  # Assuming the first detected time-related column\n",
        "    df[time_col] = pd.to_datetime(df[time_col])  # Convert to datetime format\n",
        "    df.sort_values(by=time_col, inplace=True)\n",
        "else:\n",
        "    print(\"\\nNo time-related column found in the dataset.\")"
      ],
      "metadata": {
        "id": "SS-oQlOB7OwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.CONCLUSION:**"
      ],
      "metadata": {
        "id": "4zmiW3df-5lT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**● Summarize the key insights and patterns discovered through your exploratory\n",
        "analysis.**"
      ],
      "metadata": {
        "id": "q7kGn8gbAaKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Data Distribution & Statistical Summary:**\n",
        "\n",
        " • Baseline Fetal Heart Rate (LB) has a relatively normal distribution but shows some variations across samples.\n",
        "\n",
        "\n",
        " •\tAccelerations (AC) and Fetal Movements (FM) exhibit high variability, indicating different fetal activity levels.\n",
        "\n",
        "   \n",
        "   •\tDecelerations (DL, DS, DP) have skewed distributions, which may indicate potential signs of fetal distress in some cases.\n",
        "\n",
        "•\tShort-term and long-term variability (ASTV, MSTV, ALTV, MLTV) are key indicators of fetal well-being and fluctuate significantly across samples.\n"
      ],
      "metadata": {
        "id": "RGQ4JQrr-igh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Correlation Insights:**\n",
        "\n",
        "•\tStrong positive correlation between Uterine Contractions (UC) and Prolonged Decelerations (DP) suggests that contractions may lead to prolonged heart rate decelerations.\n",
        "\n",
        "•\tASTV and ALTV show a moderate correlation, indicating that short-term and long-term heart rate variability are interconnected.\n",
        "\n",
        "•\tNo extreme multicollinearity detected, meaning most variables provide unique information and are not redundant.\n"
      ],
      "metadata": {
        "id": "MLlbtJ6Z-iSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Outliers and Anomalies:**\n",
        "\n",
        "•\tOutliers detected in Fetal Movements (FM), Uterine Contractions (UC), and Decelerations (DP), which may indicate extreme fetal activity or distress cases.\n",
        "\n",
        "•\tBoxplots revealed that some cases have abnormally high or low values in certain variables, potentially requiring further medical review."
      ],
      "metadata": {
        "id": "t8inA44C-iQg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Trends Over Time (If Temporal Data Exists):**\n",
        "\n",
        "•\tIf a time-related variable (e.g., monitoring timestamps) were available, it would help analyze fetal heart rate patterns over time.\n",
        "\n",
        "•\tContinuous monitoring of variability indicators (ASTV, MSTV) over time can improve early detection of fetal distress.\n"
      ],
      "metadata": {
        "id": "p4d8-ERK-iN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "  **● Discuss how these findings could impact decision-making or further analysis.**"
      ],
      "metadata": {
        "id": "6uApGH4wAnEQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Medical Diagnosis & Early Intervention:**\n",
        "\n",
        "•\tAccelerations and Decelerations are key indicators for assessing fetal health.\n",
        "\n",
        "•\tEarly detection of abnormal variability (ASTV, ALTV) can help doctors intervene before complications arise."
      ],
      "metadata": {
        "id": "Vd2m0T-kAyKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.\tFeature Selection for Predictive Models:**\n",
        "\n",
        "•\tHighly correlated features can be used for predictive modeling (e.g., machine learning models to classify fetal health status).\n",
        "\n",
        "•\tHandling outliers properly is essential to improve model accuracy and reduce bias."
      ],
      "metadata": {
        "id": "Az64KifgBBkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3.\tMonitoring & Alert Systems:**\n",
        "\n",
        "•\tReal-time tracking of fetal heart rate and uterine contractions can enhance fetal monitoring systems, leading to better maternal care.\n",
        "\n",
        "•\tHospitals can use automated alert systems based on fetal movement and heart rate variability to detect high-risk pregnancies."
      ],
      "metadata": {
        "id": "aRTe_Hx6BMuy"
      }
    }
  ]
}